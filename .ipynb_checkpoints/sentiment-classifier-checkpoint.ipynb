{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52375647-7493-49ef-a168-397b0f1ed782",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import SimpleRNN, LSTM, Dense, Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849a20f2-8907-49bb-ac72-628b2eb5d6ba",
   "metadata": {},
   "source": [
    "# Creating a simple model with no feature engineering. \n",
    "\n",
    "Just for inference and to create an API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a385519e-f1fc-4b0b-9a38-e614ecce1331",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 100\n",
    "max_features = 10000\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8a7dab2-3507-4805-8a83-518295cf38be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 Train data\n",
      "25000 Test data\n",
      "train shape: (25000, 100)\n",
      "test shape: (25000, 100)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(x_train), \"Train data\")\n",
    "print(len(x_test), \"Test data\")\n",
    "\n",
    "# Padding data.\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "print(\"train shape:\", x_train.shape)\n",
    "print(\"test shape:\", x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e38c171-21bd-411d-b4aa-3e9f8d8c9272",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(max_features, 200))\n",
    "model.add(SimpleRNN(200, dropout=0.2, activation='relu'))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a3960ee-8aca-45e9-92a7-557925e8953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ed09525-0a04-43a3-a18a-464c81681bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.4999999403953552\n"
     ]
    }
   ],
   "source": [
    "score, acc = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
    "print(\"Test score:\", score)\n",
    "print(\"Test accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d1f8da1-5cee-47f1-b4ba-ea110b74532b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Tried to export a function which references an 'untracked' resource. TensorFlow objects (e.g. tf.Variable) captured by functions must be 'tracked' by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly. See the information below:\n\tFunction name = b'__inference_signature_wrapper_serve_model_14076'\n\tCaptured Tensor = <ResourceHandle(name=\"seed_generator/seed_generator_state/1\", device=\"/job:localhost/replica:0/task:0/device:CPU:0\", container=\"Anonymous\", type=\"tensorflow::Var\", dtype and shapes : \"[ DType enum: 22, Shape: [2] ]\")>\n\tTrackable referencing this tensor = <tf.Variable 'seed_generator/seed_generator_state:0' shape=(2,) dtype=uint32>\n\tInternal Tensor = Tensor(\"14062:0\", shape=(), dtype=resource)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Save the model with the serving function\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaved_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msaved_model/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mserving_default\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mserve_model\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/onelab/onelab/lib/python3.11/site-packages/tensorflow/python/saved_model/save.py:1432\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, export_dir, signatures, options)\u001b[0m\n\u001b[1;32m   1430\u001b[0m \u001b[38;5;66;03m# pylint: enable=line-too-long\u001b[39;00m\n\u001b[1;32m   1431\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWriteApi(_SAVE_V2_LABEL)\n\u001b[0;32m-> 1432\u001b[0m \u001b[43msave_and_return_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexport_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1434\u001b[0m metrics\u001b[38;5;241m.\u001b[39mIncrementWrite(write_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/onelab/onelab/lib/python3.11/site-packages/tensorflow/python/saved_model/save.py:1467\u001b[0m, in \u001b[0;36msave_and_return_nodes\u001b[0;34m(obj, export_dir, signatures, options, experimental_skip_checkpoint)\u001b[0m\n\u001b[1;32m   1463\u001b[0m saved_model \u001b[38;5;241m=\u001b[39m saved_model_pb2\u001b[38;5;241m.\u001b[39mSavedModel()\n\u001b[1;32m   1464\u001b[0m meta_graph_def \u001b[38;5;241m=\u001b[39m saved_model\u001b[38;5;241m.\u001b[39mmeta_graphs\u001b[38;5;241m.\u001b[39madd()\n\u001b[1;32m   1466\u001b[0m _, exported_graph, object_saver, asset_info, saved_nodes, node_paths \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1467\u001b[0m     \u001b[43m_build_meta_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1468\u001b[0m saved_model\u001b[38;5;241m.\u001b[39msaved_model_schema_version \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1469\u001b[0m     constants\u001b[38;5;241m.\u001b[39mSAVED_MODEL_SCHEMA_VERSION)\n\u001b[1;32m   1471\u001b[0m \u001b[38;5;66;03m# Write the checkpoint, copy assets into the assets directory, and write out\u001b[39;00m\n\u001b[1;32m   1472\u001b[0m \u001b[38;5;66;03m# the SavedModel proto itself.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/onelab/onelab/lib/python3.11/site-packages/tensorflow/python/saved_model/save.py:1682\u001b[0m, in \u001b[0;36m_build_meta_graph\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1655\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a MetaGraph under a save context.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m \n\u001b[1;32m   1657\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1678\u001b[0m \u001b[38;5;124;03m  saveable_view.node_paths: _SaveableView paths.\u001b[39;00m\n\u001b[1;32m   1679\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1681\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save_context\u001b[38;5;241m.\u001b[39msave_context(options):\n\u001b[0;32m-> 1682\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_build_meta_graph_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/onelab/onelab/lib/python3.11/site-packages/tensorflow/python/saved_model/save.py:1606\u001b[0m, in \u001b[0;36m_build_meta_graph_impl\u001b[0;34m(obj, signatures, options, meta_graph_def)\u001b[0m\n\u001b[1;32m   1604\u001b[0m saveable_view \u001b[38;5;241m=\u001b[39m _SaveableView(augmented_graph_view, options)\n\u001b[1;32m   1605\u001b[0m object_saver \u001b[38;5;241m=\u001b[39m checkpoint\u001b[38;5;241m.\u001b[39mTrackableSaver(augmented_graph_view)\n\u001b[0;32m-> 1606\u001b[0m asset_info, exported_graph \u001b[38;5;241m=\u001b[39m \u001b[43m_fill_meta_graph_def\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmeta_graph_def\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmeta_graph_def\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[43m    \u001b[49m\u001b[43msaveable_view\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msaveable_view\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1609\u001b[0m \u001b[43m    \u001b[49m\u001b[43msignature_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msignatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1610\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnamespace_whitelist\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnamespace_whitelist\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1611\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_custom_gradients\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental_custom_gradients\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1612\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_saver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental_skip_saver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1613\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_debug_stripper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental_debug_stripper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1614\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdefaults\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1615\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m options\u001b[38;5;241m.\u001b[39mfunction_aliases:\n\u001b[1;32m   1617\u001b[0m   function_aliases \u001b[38;5;241m=\u001b[39m meta_graph_def\u001b[38;5;241m.\u001b[39mmeta_info_def\u001b[38;5;241m.\u001b[39mfunction_aliases\n",
      "File \u001b[0;32m~/Documents/onelab/onelab/lib/python3.11/site-packages/tensorflow/python/saved_model/save.py:970\u001b[0m, in \u001b[0;36m_fill_meta_graph_def\u001b[0;34m(meta_graph_def, saveable_view, signature_functions, namespace_whitelist, save_custom_gradients, create_saver, enable_debug_stripper, defaults)\u001b[0m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m exported_graph\u001b[38;5;241m.\u001b[39mas_default():\n\u001b[1;32m    969\u001b[0m   object_map, tensor_map, asset_info \u001b[38;5;241m=\u001b[39m saveable_view\u001b[38;5;241m.\u001b[39mmap_resources()\n\u001b[0;32m--> 970\u001b[0m   signatures \u001b[38;5;241m=\u001b[39m \u001b[43m_generate_signatures\u001b[49m\u001b[43m(\u001b[49m\u001b[43msignature_functions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobject_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefaults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m save_custom_gradients:\n\u001b[1;32m    972\u001b[0m   \u001b[38;5;66;03m# Custom gradients functions must be traced in the same context as the\u001b[39;00m\n\u001b[1;32m    973\u001b[0m   \u001b[38;5;66;03m# when they are registered.\u001b[39;00m\n\u001b[1;32m    974\u001b[0m   _trace_gradient_functions(exported_graph, saveable_view)\n",
      "File \u001b[0;32m~/Documents/onelab/onelab/lib/python3.11/site-packages/tensorflow/python/saved_model/save.py:654\u001b[0m, in \u001b[0;36m_generate_signatures\u001b[0;34m(signature_functions, object_map, defaults)\u001b[0m\n\u001b[1;32m    646\u001b[0m   mapped_inputs, exterior_argument_placeholders \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    647\u001b[0m       _map_function_arguments_to_created_inputs(\n\u001b[1;32m    648\u001b[0m           argument_inputs, signature_key, function\u001b[38;5;241m.\u001b[39mname, defaults\n\u001b[1;32m    649\u001b[0m       )\n\u001b[1;32m    650\u001b[0m   )\n\u001b[1;32m    651\u001b[0m   kwarg_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m    652\u001b[0m       \u001b[38;5;28msorted\u001b[39m(\n\u001b[1;32m    653\u001b[0m           object_map[function]\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39mstructured_input_signature[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys()))\n\u001b[0;32m--> 654\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mobject_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    655\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkwarg_name\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapped_input\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwarg_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapped_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwarg_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapped_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    657\u001b[0m \u001b[43m  \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    658\u001b[0m   signatures[signature_key] \u001b[38;5;241m=\u001b[39m signature_def_utils\u001b[38;5;241m.\u001b[39mbuild_signature_def(\n\u001b[1;32m    659\u001b[0m       _tensor_dict_to_tensorinfo(exterior_argument_placeholders),\n\u001b[1;32m    660\u001b[0m       _tensor_dict_to_tensorinfo(outputs),\n\u001b[1;32m    661\u001b[0m       method_name\u001b[38;5;241m=\u001b[39msignature_constants\u001b[38;5;241m.\u001b[39mPREDICT_METHOD_NAME,\n\u001b[1;32m    662\u001b[0m       defaults\u001b[38;5;241m=\u001b[39mdefaults\u001b[38;5;241m.\u001b[39mget(signature_key, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    663\u001b[0m   )\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signatures\n",
      "File \u001b[0;32m~/Documents/onelab/onelab/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/saved_model_exported_concrete.py:45\u001b[0m, in \u001b[0;36mExportedConcreteFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m bound_arguments \u001b[38;5;241m=\u001b[39m function_type_utils\u001b[38;5;241m.\u001b[39mcanonicalize_function_inputs(\n\u001b[1;32m     40\u001b[0m     args, kwargs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39m_function_type\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     42\u001b[0m filtered_flat_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39m_function_type\u001b[38;5;241m.\u001b[39munpack_inputs(\n\u001b[1;32m     43\u001b[0m     bound_arguments\n\u001b[1;32m     44\u001b[0m )\n\u001b[0;32m---> 45\u001b[0m export_captures \u001b[38;5;241m=\u001b[39m \u001b[43m_map_captures_to_created_tensors\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor_map\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction\u001b[38;5;241m.\u001b[39m_call_flat(filtered_flat_args, export_captures)\n",
      "File \u001b[0;32m~/Documents/onelab/onelab/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/saved_model_exported_concrete.py:74\u001b[0m, in \u001b[0;36m_map_captures_to_created_tensors\u001b[0;34m(original_captures, tensor_map, function)\u001b[0m\n\u001b[1;32m     72\u001b[0m   mapped_resource \u001b[38;5;241m=\u001b[39m tensor_map\u001b[38;5;241m.\u001b[39mget(exterior, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     73\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m mapped_resource \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 74\u001b[0m     \u001b[43m_raise_untracked_capture_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexterior\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterior\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m   export_captures\u001b[38;5;241m.\u001b[39mappend(mapped_resource)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m export_captures\n",
      "File \u001b[0;32m~/Documents/onelab/onelab/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/saved_model_exported_concrete.py:98\u001b[0m, in \u001b[0;36m_raise_untracked_capture_error\u001b[0;34m(function_name, capture, internal_capture, node_path)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m internal_capture \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     97\u001b[0m   msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mInternal Tensor = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minternal_capture\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 98\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(msg)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Tried to export a function which references an 'untracked' resource. TensorFlow objects (e.g. tf.Variable) captured by functions must be 'tracked' by assigning them to an attribute of a tracked object or assigned to an attribute of the main object directly. See the information below:\n\tFunction name = b'__inference_signature_wrapper_serve_model_14076'\n\tCaptured Tensor = <ResourceHandle(name=\"seed_generator/seed_generator_state/1\", device=\"/job:localhost/replica:0/task:0/device:CPU:0\", container=\"Anonymous\", type=\"tensorflow::Var\", dtype and shapes : \"[ DType enum: 22, Shape: [2] ]\")>\n\tTrackable referencing this tensor = <tf.Variable 'seed_generator/seed_generator_state:0' shape=(2,) dtype=uint32>\n\tInternal Tensor = Tensor(\"14062:0\", shape=(), dtype=resource)"
     ]
    }
   ],
   "source": [
    "model.save(\"sentiment-model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce9d7769-d61f-4cfe-89f1-db133b42d436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if acc > 0.85:\n",
    "#     model.save(\"sentiment-model.h5\")\n",
    "#     print(\"model saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24de0a33-b5a2-46b0-8a44-b89d3c94d2be",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ca0f694-80ca-4648-bc9c-056405dfa142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-23 10:19:25.160285: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-23 10:19:25.222676: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-07-23 10:19:25.284162: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-23 10:19:25.341448: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-23 10:19:25.357376: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-23 10:19:25.447359: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-23 10:19:26.383966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
      "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "\n",
    "# Parameters\n",
    "max_len = 100\n",
    "max_features = 10000\n",
    "\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "def preprocess_review(review, word_index, max_len):\n",
    "    tokenizer = Tokenizer(num_words=max_features)\n",
    "    tokenizer.word_index = word_index\n",
    "    sequences = tokenizer.texts_to_sequences([review])\n",
    "    \n",
    "    padded_sequence = sequence.pad_sequences(sequences, maxlen=max_len)\n",
    "    return padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4abc999-335e-46c4-b74b-fd9afcc2f50b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
      "Predicted sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"sentiment-model.h5\")\n",
    "\n",
    "new_review = \"The plot good and the characters were interesting.\"\n",
    "preprocessed_review = preprocess_review(new_review, word_index, max_len)\n",
    "prediction = model.predict(preprocessed_review)\n",
    "predicted_label = (prediction > 0.5).astype(\"int32\")\n",
    "print(f\"Predicted sentiment: {'positive' if predicted_label[0][0] == 1 else 'negative'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814ef3a3",
   "metadata": {},
   "source": [
    "Delete it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8efa016-bf7d-42d6-b1a7-641c37d5788f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "# from fastapi import FastAPI\n",
    "# from pydantic import BaseModel\n",
    "# from tensorflow.keras.preprocessing import sequence\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.datasets import imdb\n",
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "# #Parameters\n",
    "# max_len = 100\n",
    "# max_features = 10000\n",
    "\n",
    "# word_to_index = imdb.get_word_index()\n",
    "\n",
    "# model = load_model(\"sentiment-model.h5\")\n",
    "\n",
    "# def preprocess_review(review, word_to_index, max_len, max_features):\n",
    "#     tokenizer = Tokenizer(num_words=max_features)\n",
    "#     tokenizer.word_index = word_to_index\n",
    "#     sequence = tokenizer.texts_to_sequence([review])\n",
    "#     padded_sequence = sequence.pad_sequences(sequences, maxlen=max_len)\n",
    "#     return padded_sequence\n",
    "\n",
    "# app = FastAPI(title=\"IMDB Sentiment classifier API\",\n",
    "#               version=\"0.1\")\n",
    "\n",
    "# class Review(BaseModel):\n",
    "#     text:str\n",
    "\n",
    "# # @app.post(\"/predict\")\n",
    "# def predict_sentiment(review: str):\n",
    "#     preprocessed_review = preprocess_review(review.txt, word_to_index, max_len, max_features)\n",
    "\n",
    "#     prediction = model.predict(preprocessed_review)\n",
    "#     predicted_label = (prediction > 0.5).astype(\"int32\")\n",
    "\n",
    "#     sentiment = 'positive' if predicted_label[0][0] == 1 else 'negative'\n",
    "\n",
    "#     return {\"Sentiment\": sentiment, \"Probability\": prediction}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a70eb9cd-8470-4b7a-8b1e-91c3d69a1c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------*"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error hosting endpoint tensorflow-inference-2024-07-30-12-48-42-875: Failed. Reason: The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint.. Try changing the instance type or reference the troubleshooting page https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference-troubleshooting.html",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 39\u001b[0m\n\u001b[1;32m     32\u001b[0m tensorflow_model \u001b[38;5;241m=\u001b[39m TensorFlowModel(model_data\u001b[38;5;241m=\u001b[39mmodel_data,\n\u001b[1;32m     33\u001b[0m                                    role\u001b[38;5;241m=\u001b[39mrole,\n\u001b[1;32m     34\u001b[0m                                    framework_version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2.14\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     35\u001b[0m                                    image_uri\u001b[38;5;241m=\u001b[39mtensorflow_serving_image_uri,\n\u001b[1;32m     36\u001b[0m                                    sagemaker_session\u001b[38;5;241m=\u001b[39msagemaker_session)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;66;03m# Deploy the model using a basic instance type\u001b[39;00m\n\u001b[0;32m---> 39\u001b[0m predictor \u001b[38;5;241m=\u001b[39m \u001b[43mtensorflow_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitial_instance_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstance_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Print the endpoint name\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mModel deployed at endpoint: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredictor\u001b[38;5;241m.\u001b[39mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/onelab/onelab/lib/python3.11/site-packages/sagemaker/tensorflow/model.py:364\u001b[0m, in \u001b[0;36mTensorFlowModel.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe TensorFlow version \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m doesn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support EIA.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework_version\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(msg)\n\u001b[0;32m--> 364\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTensorFlowModel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    365\u001b[0m \u001b[43m    \u001b[49m\u001b[43minitial_instance_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minitial_instance_count\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    366\u001b[0m \u001b[43m    \u001b[49m\u001b[43minstance_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minstance_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdeserializer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeserializer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccelerator_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maccelerator_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformat_tags\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkms_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkms_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_capture_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_capture_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_inference_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_inference_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mserverless_inference_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mserverless_inference_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvolume_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvolume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_data_download_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_data_download_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontainer_startup_health_check_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontainer_startup_health_check_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43minference_recommendation_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minference_recommendation_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplainer_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplainer_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/onelab/onelab/lib/python3.11/site-packages/sagemaker/model.py:1746\u001b[0m, in \u001b[0;36mModel.deploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, async_inference_config, serverless_inference_config, volume_size, model_data_download_timeout, container_startup_health_check_timeout, inference_recommendation_id, explainer_config, accept_eula, endpoint_logging, resources, endpoint_type, managed_instance_scaling, inference_component_name, routing_config, **kwargs)\u001b[0m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_explainer_enabled:\n\u001b[1;32m   1744\u001b[0m     explainer_config_dict \u001b[38;5;241m=\u001b[39m explainer_config\u001b[38;5;241m.\u001b[39m_to_request_dict()\n\u001b[0;32m-> 1746\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msagemaker_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_from_production_variants\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1748\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproduction_variants\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mproduction_variant\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1749\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1750\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkms_key\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkms_key\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1751\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1752\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_capture_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_capture_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1753\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexplainer_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexplainer_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1754\u001b[0m \u001b[43m    \u001b[49m\u001b[43masync_inference_config_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43masync_inference_config_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1755\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlive_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1756\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_cls:\n\u001b[1;32m   1759\u001b[0m     predictor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor_cls(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_session)\n",
      "File \u001b[0;32m~/Documents/onelab/onelab/lib/python3.11/site-packages/sagemaker/session.py:5728\u001b[0m, in \u001b[0;36mSession.endpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict, async_inference_config_dict, explainer_config_dict, live_logging, vpc_config, enable_network_isolation, role)\u001b[0m\n\u001b[1;32m   5725\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating endpoint-config with name \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[1;32m   5726\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msagemaker_client\u001b[38;5;241m.\u001b[39mcreate_endpoint_config(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig_options)\n\u001b[0;32m-> 5728\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_endpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mendpoint_tags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwait\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlive_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlive_logging\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/onelab/onelab/lib/python3.11/site-packages/sagemaker/session.py:4586\u001b[0m, in \u001b[0;36mSession.create_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait, live_logging)\u001b[0m\n\u001b[1;32m   4583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendpoint_arn \u001b[38;5;241m=\u001b[39m res[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEndpointArn\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   4585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[0;32m-> 4586\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait_for_endpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mendpoint_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlive_logging\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlive_logging\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4587\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m endpoint_name\n",
      "File \u001b[0;32m~/Documents/onelab/onelab/lib/python3.11/site-packages/sagemaker/session.py:5371\u001b[0m, in \u001b[0;36mSession.wait_for_endpoint\u001b[0;34m(self, endpoint, poll, live_logging)\u001b[0m\n\u001b[1;32m   5365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacityError\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(reason):\n\u001b[1;32m   5366\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mCapacityError(\n\u001b[1;32m   5367\u001b[0m             message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   5368\u001b[0m             allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInService\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   5369\u001b[0m             actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   5370\u001b[0m         )\n\u001b[0;32m-> 5371\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mUnexpectedStatusException(\n\u001b[1;32m   5372\u001b[0m         message\u001b[38;5;241m=\u001b[39mmessage,\n\u001b[1;32m   5373\u001b[0m         allowed_statuses\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInService\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   5374\u001b[0m         actual_status\u001b[38;5;241m=\u001b[39mstatus,\n\u001b[1;32m   5375\u001b[0m     )\n\u001b[1;32m   5376\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m desc\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error hosting endpoint tensorflow-inference-2024-07-30-12-48-42-875: Failed. Reason: The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint.. Try changing the instance type or reference the troubleshooting page https://docs.aws.amazon.com/sagemaker/latest/dg/async-inference-troubleshooting.html"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "import boto3\n",
    "\n",
    "# Specify the region\n",
    "region = 'ap-south-1'  # Replace with your desired AWS region\n",
    "\n",
    "# Initialize Boto3 session\n",
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "# Initialize SageMaker session and role\n",
    "sagemaker_session = sagemaker.Session(boto_session=boto_session)\n",
    "role = \"arn:aws:iam::011528263565:role/dev\"\n",
    "\n",
    "# Define the S3 path for the model\n",
    "model_data = 's3://sentiment-classification-fastapi/sentiment_model.tar.gz'\n",
    "\n",
    "# Define the instance type\n",
    "instance_type = 'ml.t2.medium'\n",
    "\n",
    "# Define the TensorFlow serving image URI\n",
    "tensorflow_serving_image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework='tensorflow',\n",
    "    region=region,\n",
    "    version='2.14',  # Use the version that matches your model's TensorFlow version\n",
    "    image_scope='inference',\n",
    "    instance_type=instance_type\n",
    ")\n",
    "\n",
    "# Create a TensorFlowModel object\n",
    "tensorflow_model = TensorFlowModel(model_data=model_data,\n",
    "                                   role=role,\n",
    "                                   framework_version='2.14',\n",
    "                                   image_uri=tensorflow_serving_image_uri,\n",
    "                                   sagemaker_session=sagemaker_session)\n",
    "\n",
    "# Deploy the model using a basic instance type\n",
    "predictor = tensorflow_model.deploy(initial_instance_count=1, instance_type=instance_type)\n",
    "\n",
    "# Print the endpoint name\n",
    "print(f'Model deployed at endpoint: {predictor.endpoint_name}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onelab",
   "language": "python",
   "name": "onelab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
